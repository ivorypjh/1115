{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d395839c",
   "metadata": {},
   "source": [
    "## 공용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b72252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬\n",
    "# ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해 %matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "    \n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# Jupyter Notebook의 출력을 소수점 이하 3자리로 제한\n",
    "%precision 3\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 시드 고정\n",
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e9295",
   "metadata": {},
   "source": [
    "## 텍스트 파일에서 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34560d",
   "metadata": {},
   "source": [
    "### 세부 장르 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52d3108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가져오기\n",
    "\n",
    "origin_data = pd.read_excel('./3차_VOD_2308.xlsx')\n",
    "sub_data = origin_data[['ct_cl','genre_of_ct_cl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c0ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세부 장르를 저장할 리스트\n",
    "detail_genre_list = []\n",
    "\n",
    "for data in sub_data.iterrows():\n",
    "    # 데이터 구분\n",
    "    ct_cl = data[1]['ct_cl']\n",
    "    genre = data[1]['genre_of_ct_cl']\n",
    "    \n",
    "    # / 가 포함되어 있으면 파일 경로에 문제가 생기므로 & 로 대체\n",
    "    if '/' in ct_cl:\n",
    "        ct_cl = ct_cl.replace('/', '&')\n",
    "    if '/' in genre:\n",
    "        genre = genre.replace('/', '&')\n",
    "    \n",
    "    detail_genre = ct_cl + '-' + genre\n",
    "    if detail_genre not in detail_genre_list:\n",
    "        detail_genre_list.append(detail_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9992fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세부 장르 데이터 저장\n",
    "output_file = open('./text files/detail_genre.txt', 'w', encoding = 'utf8')\n",
    "\n",
    "for item in detail_genre_list:\n",
    "    output_file.write(item + '\\n')\n",
    "    \n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53cf4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일에서 세부 장르 데이터 가져오기\n",
    "\n",
    "open_file = open('./text files/detail_genre.txt', 'r', encoding = 'utf8')\n",
    "text = open_file.read()\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa51e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 파일에서 읽어온 데이터 확인\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3640471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bab6e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_list 의 마지막에 공백이 추가되므로 공백 제거\n",
    "data_list = data_list[:-2]\n",
    "# 확인\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e277a",
   "metadata": {},
   "source": [
    "### 세부 장르 별 요약 줄거리 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27305e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260519e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('./text files/' + '영화-코미디' + '.txt', 'r', encoding = 'utf8')\n",
    "text = open_file.read()\n",
    "\n",
    "# 읽어온 텍스트 데이터에서 형태소를 분석하고 단어만 저장\n",
    "spliter = Twitter()\n",
    "nouns = spliter.nouns(text)\n",
    "# nouns 는 각 단어를 str 형태로 리스트에 저장\n",
    "\n",
    "#print(nouns) # 형태소 확인\n",
    "\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1df17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for item in nouns:\n",
    "    if item not in new_list:\n",
    "        new_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c50f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642\n",
      "488\n"
     ]
    }
   ],
   "source": [
    "print(len(nouns))\n",
    "print(len(new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3adf98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file = open('./text files/' + 'test' + '.txt', 'w', encoding = 'utf8')\n",
    "\n",
    "for item in new_list:\n",
    "    open_file.write(item + '\\n')\n",
    "\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cb63fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 세부 장르의 줄거리가 저장된 파일에서 데이터 읽어오고 단어만 추출해서 저장 - 종합\n",
    "for detail_genre in data_list:\n",
    "    open_file = open('./text files/' + detail_genre + '.txt', 'r', encoding = 'utf8')\n",
    "    text = open_file.read()\n",
    "    \n",
    "    # 읽어온 텍스트 데이터에서 단어만 추출\n",
    "    spliter = Twitter()\n",
    "    nouns = spliter.nouns(text)\n",
    "    \n",
    "    # 추출한 단어에서 중복을 제거\n",
    "    new_list = []\n",
    "    for item in nouns:\n",
    "        if item not in new_list:\n",
    "            new_list.append(item)\n",
    "            \n",
    "    # 중복이 없는 단어를 파일로 저장\n",
    "    word_file = open('./text files/' + detail_genre + '_words.txt', 'w', encoding = 'utf8')\n",
    "    for item in new_list:\n",
    "        word_file.write(item + '\\n')\n",
    "\n",
    "    # 파일 닫기\n",
    "    word_file.close()\n",
    "    open_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b36241cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict_data = {}\n",
    "\n",
    "# 각 세부 장르 별로 단어 리스트 생성하고 저장\n",
    "for detail_genre in data_list:\n",
    "    # 각 세부 장르에 대해 단어 데이터 가져오기\n",
    "    open_file = open('./text files/' + detail_genre + '_words.txt', 'r', encoding = 'utf8')\n",
    "    text = open_file.read()\n",
    "    \n",
    "    # 파일 닫기\n",
    "    open_file.close()\n",
    "    \n",
    "    # 각 단어 분리하기\n",
    "    data_list = text.split('\\n')\n",
    "    data_list = data_list[:-2] # 마지막의 공백 제외\n",
    "    \n",
    "    # 단어 리스트를 dict 형태로 저장\n",
    "    word_dict_data[detail_genre] = data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63839239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인\n",
    "# print(word_dict_data['TV 시사&교양-기타'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385e123",
   "metadata": {},
   "source": [
    "### 문장의 단어 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcc0189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a0bdbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'TV 시사&교양-기타' 장르에 대해서 단어 벡터화 테스트\n",
    "\n",
    "okt = Okt()\n",
    "vectorizer = CountVectorizer(min_df = 0.05)\n",
    "contents_tokens = word_dict_data['TV 시사&교양-기타']\n",
    "\n",
    "\n",
    "# 벡터화를 위해 단어들을 가지고 문장 생성\n",
    "contents_for_vect = []\n",
    "sentence = ''\n",
    "# 토큰 단위로 구분된 문장을 생성\n",
    "for content in contents_tokens:\n",
    "    sentence += ' ' + content\n",
    "\n",
    "# 생성한 문장을 리스트에 추가\n",
    "contents_for_vect.append(sentence)\n",
    "# 확인\n",
    "#print(contents_for_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9d7515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가게' '가까이' '가나' ... '희망' '히데' '히트']\n"
     ]
    }
   ],
   "source": [
    "# 피처 벡터화\n",
    "\n",
    "X = vectorizer.fit_transform(contents_for_vect)\n",
    "# 피처 확인\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fecd761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 1 1 1]]\n",
      "1411\n",
      "1411\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())\n",
    "print(X.shape[1])\n",
    "print(len(X.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "414375ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['가게' '가까이' '가나' ... '희망' '히데' '히트']\n",
      "  (0, 458)\t1\n",
      "  (2, 602)\t1\n",
      "  (4, 1067)\t1\n",
      "  (5, 253)\t1\n",
      "  (7, 821)\t1\n",
      "  (8, 605)\t1\n",
      "  (11, 1071)\t1\n",
      "  (12, 504)\t1\n",
      "  (14, 427)\t1\n",
      "  (16, 307)\t1\n",
      "  (17, 1201)\t1\n"
     ]
    }
   ],
   "source": [
    "# 유사도를 측정할 줄거리 생성 - 9월 데이터 중 하나 활용\n",
    "new_content = '밀실 안의 살인자, 정유정은 누구인가? 20대 또래 여성을 살해한 정유정의 정체와 범행 동기가 무엇인지에 대해 추적해 본다.'\n",
    "\n",
    "# 문장 토큰화\n",
    "spliter = Twitter()\n",
    "words = spliter.nouns(new_content)\n",
    "# 확인\n",
    "# print(words)\n",
    "\n",
    "# 테스트 문장을 피처 벡터화\n",
    "new_content_vect = vectorizer.transform(words)\n",
    "print(new_content_vect.toarray())\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(new_content_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626a7f9",
   "metadata": {},
   "source": [
    "## 줄거리 거리 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "660e64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터와 훈련 데이터 거리 확인\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "#거리 구해주는 함수 생성\n",
    "def dist_raw(v1, v2):\n",
    "    delta = v1 - v2\n",
    "    return sp.linalg.norm(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47ebd99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 문장과의 거리: 159.33\n"
     ]
    }
   ],
   "source": [
    "post_vec = X.getrow(0)\n",
    "#print(post_vec.toarray())\n",
    "#print(new_content_vect.toarray())\n",
    "\n",
    "aaaa = new_content_vect.toarray()\n",
    "bbbb = post_vec.toarray()\n",
    "\n",
    "distance = dist_raw(aaaa, bbbb)\n",
    "print(\"테스트 문장과의 거리: %.2f\" %(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011439cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#거리 구해주는 함수\n",
    "def dist_raw(v1, v2):\n",
    "    delta = v1 - v2\n",
    "    return sp.linalg.norm(delta.toarray())\n",
    "\n",
    "distance = dist_raw(new_content_vect, post_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
